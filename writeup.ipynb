{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning\n",
    "\n",
    "## Required Files\n",
    "### Are all required files submitted?\n",
    "The submission includes a model.py file, drive.py, model.h5, a writeup report and a running video.\n",
    "* model.py containing the script to create and train the model\n",
    "* drive.py for driving the car in autonomous mode\n",
    "* model.h5 containing a trained convolution neural network \n",
    "* writeup.ipynb\n",
    "* run1.mp4, a test1 with speed of 30mph.\n",
    "\n",
    "## Quality of Code\n",
    "### Is the code functional?\n",
    "The model provided can be used to successfully operate the simulation.\n",
    "I have modified the drive.py in order to chop the image from the simulator. \n",
    "I cut 40pixel at top and 20pixel at bottom.\n",
    "\n",
    "### Is the code usable and readable?\n",
    "The code is ver short and therefore easy to read, Despite of that I have added comments and references.\n",
    "\n",
    "\n",
    "## Model Architecture and Training Strategy\n",
    "### Has an appropriate model architecture been employed for the task?\n",
    "I have tryied a variety of models but eventually I have use the NVidia architectura but with an input of 100x320 since I have chop the image 40pixel top and 20pixel bottom. \n",
    "\n",
    "I don't use the last convolutional layer 64@1x18.\n",
    "\n",
    "The reference to the paper is:\n",
    "\n",
    "http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "\n",
    "Here is the code definning the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Preprocess incoming data, centered around zero with small standard deviation \n",
    "# From NVIDIA paper: http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "# In my case the input image is 120x320 not 66x220\n",
    "model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "        input_shape=( row, col,ch),\n",
    "        output_shape=(row, col, ch)))\n",
    "model.add(Conv2D(24, 5, 5, input_shape=(row, col, ch)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add((Dropout(0.5)))\n",
    "model.add(Conv2D(36, 5, 5))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add((Dropout(0.5)))\n",
    "model.add(Conv2D(48, 3, 3))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add((Dropout(0.5)))\n",
    "model.add(Conv2D(64, 3, 3))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add((Dropout(0.5)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Has an attempt been made to reduce overfitting of the model?\n",
    "I use dropout after each convolutional layer.\n",
    "I use data augmentation in order to reduce overfitting, after reading this two blogs:\n",
    "\n",
    "* https://chatbotslife.com/using-augmentation-to-mimic-human-driving-496b569760a9#.zc82yp45t\n",
    "* https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "I use brightness, affine transform, only on X axis, flipped image and shadow augmentation.\n",
    "\n",
    "Here you can see the code, from Vivek Yadav:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From: https://chatbotslife.com/using-augmentation-to-mimic-human-driving-496b569760a9#.o92uic4yq\n",
    "# Data aumentation with brightness, shadow and transformations\n",
    "def augment_brightness_camera_images(image):\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    random_bright = .25+np.random.uniform()\n",
    "    #print(random_bright)\n",
    "    image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1\n",
    "def trans_image(image,steer,trans_range):\n",
    "    # Translation\n",
    "    cols=image.shape[1]\n",
    "    rows=image.shape[0]\n",
    "    tr_x = trans_range*np.random.uniform()-trans_range/2\n",
    "    steer_ang = steer + tr_x/trans_range*2*.2\n",
    "    tr_y = 40*np.random.uniform()-40/2\n",
    "    tr_y = 0\n",
    "    Trans_M = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "    image_tr = cv2.warpAffine(image,Trans_M,(cols,rows))\n",
    "    return image_tr,steer_ang\n",
    "def add_random_shadow(image):\n",
    "    top_y = 320*np.random.uniform()\n",
    "    top_x = 0\n",
    "    bot_x = 160\n",
    "    bot_y = 320*np.random.uniform()\n",
    "    image_hls = cv2.cvtColor(image,cv2.COLOR_RGB2HLS)\n",
    "    shadow_mask = 0*image_hls[:,:,1]\n",
    "    X_m = np.mgrid[0:image.shape[0],0:image.shape[1]][0]\n",
    "    Y_m = np.mgrid[0:image.shape[0],0:image.shape[1]][1]\n",
    "    shadow_mask[((X_m-top_x)*(bot_y-top_y) -(bot_x - top_x)*(Y_m-top_y) >=0)]=1\n",
    "    #random_bright = .25+.7*np.random.uniform()\n",
    "    if np.random.randint(2)==1:\n",
    "        random_bright = .5\n",
    "        cond1 = shadow_mask==1\n",
    "        cond0 = shadow_mask==0\n",
    "        if np.random.randint(2)==1:\n",
    "            image_hls[:,:,1][cond1] = image_hls[:,:,1][cond1]*random_bright\n",
    "        else:\n",
    "            image_hls[:,:,1][cond0] = image_hls[:,:,1][cond0]*random_bright    \n",
    "    image = cv2.cvtColor(image_hls,cv2.COLOR_HLS2RGB)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have the model parameters been tuned appropriately?\n",
    "Learning rate parameters are chosen with explanation, or an Adam optimizer is used.\n",
    "\n",
    "### Is the training data chosen appropriately?\n",
    "I have use the data from the course. In order to get robustness and reduce overffiting.\n",
    "I borrow a usb steering wheel in order to get data, but eventualy it has not been necessary since I have been able to keep the car on the track, even though trainning just with left, center and right images is more difficult.\n",
    "\n",
    "## Architecture and Training Documentation\n",
    "### Is the solution design documented?\n",
    "\n",
    "The README thoroughly discusses the approach taken for deriving and designing a model architecture fit for solving the given problem.\n",
    "\n",
    "### Is the model architecture documented?\n",
    "I have used the Nvidia network with some differences.\n",
    "\n",
    "His is the original Nvidia model:\n",
    "\n",
    "![alt text](images/nvidianet.png \"Nvidia Neural Network\")\n",
    "\n",
    "There are two main differences on my model, the code of the model is above:\n",
    "* I use an input of 100x320 since I have chop the image 40pixel top and 20pixel bottom.\n",
    "* I don't use the last convolutional layer 64@1x18.\n",
    "\n",
    "Information of keras with the total numbers of parameters is:\n",
    "\n",
    "![alt text](images/kerasnet.png \"Keras Neural Network\")\n",
    "\n",
    "\n",
    "\n",
    "### Is the creation of the training dataset and training process documented?\n",
    "\t\n",
    "\n",
    "The README describes how the model was trained and what the characteristics of the dataset are. Information such as how the dataset was generated and examples of images from the dataset should be included.\n",
    "\n",
    "## Simulation\n",
    "### Is the car able to navigate correctly on test data?\n",
    "\t\n",
    "\n",
    "No tire may leave the drivable portion of the track surface. The car may not pop up onto ledges or roll over any surfaces that would otherwise be considered unsafe (if humans were in the vehicle).\n",
    "\n",
    "Suggestions to Make Your Project Stand Out!\n",
    "Track Two\n",
    "\n",
    "The simulator contains two tracks. To meet specifications, the car must successfully drive around track one. Track two is more difficult. See if you can get the car to stay on the road for track two as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
